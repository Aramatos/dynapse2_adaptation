{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=8> Network Tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common Python Packages\n",
    "from pickle import TRUE\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timeout_decorator\n",
    "\n",
    "#dynapse2 spikegen imports\n",
    "from lib.dynapse2_util import *\n",
    "from lib.dynapse2_network import Network\n",
    "from lib.dynapse2_spikegen import send_events,get_fpga_time, send_virtual_events, poisson_gen, isi_gen,regular_gen\n",
    "from lib.dynapse2_raster import *\n",
    "from lib.dynapse2_obj import *\n",
    "\n",
    "#Statistics imports\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import butter, filtfilt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import linregress\n",
    "from itertools import product\n",
    "#my imports\n",
    "from adaptation import pc_single,ff,pc_pv_sst,ff_network\n",
    "from adaptation_lib.spike_stats import *\n",
    "from adaptation_lib.dynapse_setup import *\n",
    "from adaptation_lib.graphing import *\n",
    "from configs import neuron_configs_bio\n",
    "\n",
    "\n",
    "# Determine the user's home directory\n",
    "home_directory = os.path.expanduser(\"~\")\n",
    "# Path to the Documents directory\n",
    "documents_path = os.path.join(home_directory, \"Documents\")\n",
    "# Path to the dynapse-se2-data directory within Documents\n",
    "base_path = os.path.join(documents_path, \"dynapse-se2-data\")\n",
    "# Path to the random tests\n",
    "random_search_path = os.path.join(documents_path, \"network_random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=7> Manual Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<samna.device.DeviceInfo object at 0x7fdc76734ab0>]\n"
     ]
    }
   ],
   "source": [
    "[board,profile_path,number_of_chips]=obtain_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_slope(time_axis, ff_windows_sst):\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(time_axis, ff_windows_sst)\n",
    "    return slope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Latches\n",
      "Setting up network\n",
      "Adding connections\n",
      "\n",
      "Setting monitors\n",
      "20 100 10\n",
      "\n",
      "PC Neurons\n",
      "\n",
      "[221, 235, 201, 211, 230, 252, 237, 234, 236, 250, 169, 180, 183, 189, 204, 227, 242, 188, 194, 207, 248, 251, 203, 215, 219, 228, 196, 165, 171, 181, 195, 220, 222, 244, 149, 156, 164, 179, 205, 206, 217, 226, 238, 254, 148, 157, 158, 210, 214, 232, 245, 246, 131, 152, 161, 163, 167, 173, 176, 198, 200, 209, 231, 233, 113, 146, 170, 190, 192, 197, 229, 247, 249, 115, 118, 139, 141, 143, 159, 160, 166, 186, 202, 213, 218, 107, 134, 151, 155, 162, 177, 191, 216, 225, 243, 116, 126, 130, 140, 145]\n",
      "\n",
      "PV Neurons\n",
      "\n",
      "[255, 252, 202, 233, 239, 223, 206, 238, 251, 173, 207, 253, 254, 186, 199, 221, 235, 237, 191, 213]\n",
      "\n",
      "PV Neurons\n",
      "\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "\n",
      "All configurations done!\n",
      "\n",
      "Input events created\n",
      "initilize run dynapse\n",
      "initilize run dynapse\n",
      "\n",
      "getting fpga time\n",
      "\n",
      "\n",
      "setting virtual neurons\n",
      "\n",
      "Simulation done\n",
      "PC_CV_average: 0.06 PV_CV_average: 0.3 SST_CV_average: 0.0\n",
      "PC_synchrony: 1.0 PV_CV_average: 1.0 SST_CV_average: nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 249 and the array at index 1 has size 250",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m fvt_fig \u001b[39m=\u001b[39m frequency_vs_time_plot(frequency_over_time(test_config, output_events), test_config, save\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, annotate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,neuron_config\u001b[39m=\u001b[39mneuron_config)\n\u001b[1;32m     40\u001b[0m [time_axis, ff_windows_pc, ff_windows_pv, ff_windows_sst] \u001b[39m=\u001b[39m fot_output\n\u001b[0;32m---> 41\u001b[0m slope \u001b[39m=\u001b[39m calculate_slope(time_axis, ff_windows_sst)\n\u001b[1;32m     42\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSimulation \u001b[39m\u001b[39m{\u001b[39;00msuccessful_simulations\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m completed successfully!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m successful_simulations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m, in \u001b[0;36mcalculate_slope\u001b[0;34m(time_axis, ff_windows_sst)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_slope\u001b[39m(time_axis, ff_windows_sst):\n\u001b[0;32m----> 2\u001b[0m     slope, intercept, r_value, p_value, std_err \u001b[39m=\u001b[39m linregress(time_axis, ff_windows_sst)\n\u001b[1;32m      3\u001b[0m     \u001b[39mreturn\u001b[39;00m slope\n",
      "File \u001b[0;32m~/miniconda3/envs/dynapse2/lib/python3.10/site-packages/scipy/stats/_stats_mstats_common.py:160\u001b[0m, in \u001b[0;36mlinregress\u001b[0;34m(x, y, alternative)\u001b[0m\n\u001b[1;32m    155\u001b[0m ymean \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(y, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    157\u001b[0m \u001b[39m# Average sums of square differences from the mean\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39m#   ssxm = mean( (x-mean(x))^2 )\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39m#   ssxym = mean( (x-mean(x)) * (y-mean(y)) )\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m ssxm, ssxym, _, ssym \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mcov(x, y, bias\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mflat\n\u001b[1;32m    162\u001b[0m \u001b[39m# R-value\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m#   r = ssxym / sqrt( ssxm * ssym )\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mif\u001b[39;00m ssxm \u001b[39m==\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m ssym \u001b[39m==\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# If the denominator was going to be 0\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/dynapse2/lib/python3.10/site-packages/numpy/lib/function_base.py:2639\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2637\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m rowvar \u001b[39mand\u001b[39;00m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2638\u001b[0m         y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mT\n\u001b[0;32m-> 2639\u001b[0m     X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate((X, y), axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m   2641\u001b[0m \u001b[39mif\u001b[39;00m ddof \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2642\u001b[0m     \u001b[39mif\u001b[39;00m bias \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 249 and the array at index 1 has size 250"
     ]
    }
   ],
   "source": [
    "import random\n",
    "neuron_config=neuron_configs_bio.config()\n",
    "\n",
    "neuron_config['PC_Adaptation'] = True\n",
    "neuron_config['duration'] = 1\n",
    "neuron_config['input_type'] = 'Regular'\n",
    "neuron_config['in_freq'] = 30\n",
    "\n",
    "def randomize_config(neuron_config):\n",
    "    neuron_config['SST_W0'] = [random.randint(1, 3), random.randint(10, 250)]\n",
    "    neuron_config['SST_W1'] = [random.randint(1, 3), random.randint(10, 250)]\n",
    "    neuron_config['SST_AMPA_GAIN'] = [random.randint(1, 3), random.randint(10, 250)]\n",
    "    neuron_config['SST_AMPA_TAU'] = [random.randint(0, 1), random.randint(10, 250)]# 80-100\n",
    "    neuron_config['SST_LEAK']= [1, random.randint(80, 100)] # 30-20\n",
    "    neuron_config['Input_SST'] = random.uniform(.05, .5)\n",
    "    neuron_config['PC_SST'] = random.uniform(.05, .5)\n",
    "\n",
    "    return neuron_config\n",
    "\n",
    "\n",
    "@timeout_decorator.timeout(40)  # Set a 5-second timeout\n",
    "\n",
    "def run_simulation(neuron_config):\n",
    "    return pc_pv_sst.pc_pv_sst(\n",
    "        board=board,\n",
    "        profile_path=profile_path,\n",
    "        number_of_chips=number_of_chips,\n",
    "        neuron_config=neuron_config\n",
    "    )\n",
    "\n",
    "successful_simulations = 0\n",
    "\n",
    "for i in range(1000):  # Example: Keep trying different configurations until 100 successful simulations\n",
    "    neuron_config = randomize_config(neuron_config)  # Assuming you've updated randomize_config without an argument\n",
    "    try:\n",
    "        [output_events, test_config] = run_simulation(neuron_config)\n",
    "        [cv_values, synchrony_values] = run_dynamic_anal(output_events, test_config)\n",
    "        fot_output= frequency_over_time(test_config, output_events)\n",
    "        fvt_fig = frequency_vs_time_plot(frequency_over_time(test_config, output_events), test_config, save=True, annotate=True,neuron_config=neuron_config)\n",
    "        [time_axis, ff_windows_pc, ff_windows_pv, ff_windows_sst] = fot_output\n",
    "        slope = calculate_slope(time_axis, ff_windows_sst)\n",
    "        print(f\"Simulation {successful_simulations + 1} completed successfully!\")\n",
    "        successful_simulations += 1\n",
    "        \n",
    "        if successful_simulations >= 2000: # Stop after 100 successful simulations\n",
    "            break\n",
    "    except timeout_decorator.TimeoutError:\n",
    "        print(\"Simulation timed out, trying again with new parameters...\")\n",
    "\n",
    "print(\"Completed 100 successful simulations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynapse2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
